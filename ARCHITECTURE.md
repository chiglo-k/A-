# Решение по "Арихтектуре данных для геопространственной платформы"

## Краткое резюме

`Что за платформа, какие основные типы данных вы учитываете и какая общая идея архитектуры.`

Для выполнения можно использовать как открытое ПО (YTsaurus/Kiparis) так и облачную платформу (YandexCloud).
Используем YandexCloud, т.к. данная платформа позволит использовать необходимые инструменты для построения Data LakeHouse.
Данный вид хранилища выбран т.к. в проекте используются как структурированные данные, так и неструктурированный, файлы.


При выборе подхода Data LakeHouse ориентировался на использование данных как для аналитики, хранения данных, так и для обучения ИИ на основе файлов в объектном хранилище.

## Основные требования (списком).

`5–10 ключевых требований, которые вы считаете важными (latency, хранение исторических данных, интеграции, аналитика и т.п.).`

- Ведение SCD (позволяет видеть изменения по данным на временном отрезке);
- Разделение инструментов под аналитику, хранение данных (например PostgreSQL + PostGIS для хранения и аналитики геоданных, ClickHouse для аналитики на большом массиве данных);
- Подходит для временных рядов;
- Возможность снижения затрат за счет открытого ПО;
- Интеграция с BI-системами, аналитическими системами (на YandexCloud можжно вывсти данные в DataLens, для аналитиков поднять Zeppelin на базе PySpark);
- Возможность автоматизации процессов бэкапа данных, тех. поддержки 24/7;
- Доступ к объектному хранилищу;
- Возможность интеграции всех сервисов в одном месте.

## Целевая архитектура (high‑level).  

### Ingestion (Поступление данных)

    Спутниковые данные: Sentinel-1/2 (SAFE, JP2, GeoTIFF), GIBS (WMS/WFS/WMS-T слои) [1].
    Прогнозные модели: GFS, Global Ocean Physics (NetCDF, GRIB2) [1].
    Навигационные данные: AIS (JSON, CSV, бинарные потоки от провайдеров).
    Оперативные данные: Данные отчетов, фото/видео (PDF, DOCX, JPG, PNG) [1].
    Открытые/ручные данные: Файлы CSV, XLSX, TXT, загружаемые пользователями [1].

ETL/ELT процессы:

    ETL/ELT процессы: Используются для парсинга и загрузки  данных в их место хранения.
    1. Потоковая передача (Streaming): Для данных AIS и телеметрии (Kafka);
    2. Загрузка файлов: API-сервис для приема тяжелых файлов в S3;
    3. Airflow для обработки данных из БД, S3;
    4. Pentho DE для обработки локальных файлов.
    
### Storage (Хранение данных)

    PostgreSQL + PostGIS (Реляционное, Геопространственное):
        Данные: Актуальные геометрии (SHP, GeoJSON), навигационные маршруты, метаданные (геотеги, атрибуты), мастер-данные.
        Назначение: Хранение «горячих» транзакционных данных с высокими требованиями к ACID и сложными пространственными запросами;
    ClickHouse (Колоночное, Аналитическое):
        Данные: История AIS-треков, временные ряды метеоданных, логи обработки, исторические массивы данных.
        Назначение: Сверхбыстрая аналитика (OLAP) больших объемов данных (десятки ТБ+), агрегация и сжатие данных;
    S3 Object Storage (Объектное хранилище):
        Данные: Исходные тяжелые файлы (GeoTIFF, NetCDF, GRIB2), спутниковые снимки Sentinel, фото/видео, отчетная документация (PDF, DOCX).
        Назначение: Дешевое, масштабируемое хранение «холодных» и «замороженных» бинарных данных, бэкапов.

### Processing (Обработка и агрегация)

    Обработка геоданных (внутри Postgres/PostGIS):
        Парсинг KML/GPX в геометрии.
        Пространственный анализ: пересечения, буферизация, расчет расстояний, топологические проверки;
    Обработка растровых данных (Python/Spark):
        Нейросети: Применение моделей к снимкам Sentinel-1/2 для дешифровки (например, выделение контуров льда, разливов нефти);
        Пост-процессинг: Преобразование результатов нейросетей из растра в вектор (растеризация в полигоны для записи в PostGIS);
        Парсинг метеоданных: Преобразование GRIB2/NetCDF в растровые слои или точечные данные для ClickHouse.
    Агрегация данных (внутри ClickHouse):
        Агрегация исторических треков AIS по часам/дням;
        Расчет средних значений метеопараметров по регионам.

### Serving (Использование данных)

    WEB GIS (Картографический сервис):
        Использует WMS/WFS-слои из PostGIS для отображения актуальной геометрии;
        Отображает растровые слои (GeoTIFF) из S3;
    Отчеты и BI-системы:
        Подключаются к ClickHouse для построения аналитических отчетов и дашбордов;
        Генерируют PDF/XLSX документы, сохраняемые в S3;
    API-сервисы:
        Предоставляют микросервисам доступ к мастер-данным в PostgreSQL;
        Предоставляют ссылки на файлы в S3;
    Прогнозные модели (ML Ops):
        Потребляют агрегированные данные из ClickHouse и актуальные данные из PostGIS для переобучения моделей.

## Технологический стек

Для реализации Data LakeHouse применяется слудующий тех.стек:

- Kafka (обработка потоковой инрформации);
- PySpark/Zeppelin (обработка информации, ее анализ);
- Airflow (обработка информации, пайплайн между местами хранения данных);
- Pentaho DE (обработка инфомрации на локальных системах с последующей загрузкой в целевые базы данных);
- PostgreSQL + GIS (хранение оперативных данных, геоданных);
- ClickHouse (Хранение данных);
- S3;
- Docker (для развертки допю приложений);
- BI-инструменты для визуализаций.

## Пара ключевых решений и trade‑off’ов.

`Выберите 1–2 наиболее важных решения (например, выбор геохранилища или подход к data lake)`

1. Выбор Data LakeHouse -- это позволяет объеденить подход к хранению структурированных данных и файлов, данный подход позволяет достигнуть целей наиболее полно.
2. Использование YandexCloud -- использование облака позволяет использовать все сервисы в интеграции друг с другом, упрощает управление инфраструктурой, профедении процессов контроля данными.

**Альтернатива** YTsaurus/Kiparis полностью бесплатное ПО, которое позволит также построить Data LakeHouse инфраструктуру.
Существенный недостаток необходимость поддержания специалистов по DevOps (ПО бесплатное так что, об автоматизации и прочих плюсах облака можо забыть).


## Риски и упрощения.

1. Настройка сервисов (есть проблемы с поднятием kafka проблемы в памяти <раньше были>, Yandex DataSphere для Data Science, ИИ и т.д. <сложно администрированое решение>;
2. Поднятие расценок на сервисы (изменение НДС как пример);
3. Проблемы на стороне Yandex, что приведет к проблеме доступа к данным;

Упрощения:

- Не рассматривал на YTsaurus;
- Возможно из-за специфики данных потребуется пересмотреть стек;
- UML диаграмму (появиться после, но не укладывается во время). 












